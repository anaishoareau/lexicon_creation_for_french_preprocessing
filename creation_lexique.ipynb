{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création de lexique.txt pour le package french_preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:02:40.338947Z",
     "start_time": "2019-06-25T08:02:38.358125Z"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import nltk\n",
    "from nltk.tag import StanfordPOSTagger\n",
    "import csv\n",
    "import os\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation du StanfordPOSTagger\n",
    "\n",
    "Il faut peut-être changer les path pour le StanfordPOSTagger et Java (JRE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:02:40.348852Z",
     "start_time": "2019-06-25T08:02:40.340905Z"
    }
   },
   "outputs": [],
   "source": [
    "jar = './stanford-postagger-full-2018-10-16/stanford-postagger-3.9.2.jar'\n",
    "model = './stanford-postagger-full-2018-10-16/models/french.tagger'\n",
    "java_path = \"C:/Program Files (x86)/Java/jre1.8.0_241/bin/java.exe\"\n",
    "\n",
    "os.environ['JAVAHOME'] = java_path\n",
    "pos_tagger = StanfordPOSTagger(model, jar, encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Récupération du lexique du  FrenchLefffLemmatizer et modification des tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chargement du lexique : la LEFFF_TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:02:42.705553Z",
     "start_time": "2019-06-25T08:02:40.352841Z"
    }
   },
   "outputs": [],
   "source": [
    "from french_lefff_lemmatizer.french_lefff_lemmatizer import FrenchLefffLemmatizer\n",
    "lemmatizer = FrenchLefffLemmatizer()\n",
    "lemmatizer.LEFFF_TABLE\n",
    "tab = lemmatizer.LEFFF_TABLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Liste des tags de la LEFFF_TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:02:43.269042Z",
     "start_time": "2019-06-25T08:02:42.708544Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nc', 'np', 'v', 'adj', 'parento', 'parentf', 'ponctw', 'adv', 'nc_2', 'pro', 'det', 'coo', 'auxAvoir', 'cld', 'clneg', 'clr', 'auxEtre', 'pri', 'prep', 'csu', 'etr', 'cln', 'prel', 'poncts', 'cll', 'pres', 'sbound', 'cla', 'advneg', 'clg', 'adjPref', 'advPref', ':GR', 'GA:', 'GP:', 'GN:', 'PV:', ':GA', 'NV:', ':PV', ':GN', ':GP', ':NV', 'GR:', 'ce', 'suffAdj', 'ilimp', 'clar', 'cldr', 'meta', 'epsilon', 'caimp', 'que', 'que_restr']\n"
     ]
    }
   ],
   "source": [
    "# Donne la liste des tags de la LEFFF_TABLE\n",
    "tag_list = []\n",
    "tag_list_compt = [0 for i in range(100)]\n",
    "for key in tab:\n",
    "    for tag in tab[key].keys():\n",
    "        if tag not in tag_list:\n",
    "            tag_list.append(tag)\n",
    "            ind = tag_list.index(tag)\n",
    "            tag_list_compt[ind] += 1\n",
    "        else:\n",
    "            ind = tag_list.index(tag)\n",
    "            tag_list_compt[ind] += 1\n",
    "\n",
    "print(tag_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Catégorisation des différents tags pour l'uniformisation\n",
    "\n",
    "Liste des tags uniformisés : ['v', 'nc', 'adj', 'c', 'npp', 'adv', 'det', 'pro', 'prep', 'i', 'ponct', 'cl', 'et']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:02:43.292980Z",
     "start_time": "2019-06-25T08:02:43.271039Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tags à modifier en 'npp'\n",
    "tag_list_np = ['np']\n",
    "# Tags à modifier en 'cl'\n",
    "tag_list_cl = ['cld','cla','clr','clneg','clg','cll','cln', 'cldr', 'clar']\n",
    "# Tags à modifier en 'i'\n",
    "tag_list_interjection = ['pres']\n",
    "# Tags à modifier en 'pro'\n",
    "tag_list_pr = ['prel']\n",
    "# Tags à modifier en 'ponct'\n",
    "tag_list_ponct = ['poncts','ponctw']\n",
    "# Tags à modifier en 'adj'                \n",
    "tag_list_adj = ['adjPref','suffAdj']\n",
    "# Tags à modifier en 'adv'\n",
    "tag_list_adv = ['advneg','advPref']\n",
    "# Tags à modifier en 'c'\n",
    "tag_list_cs = ['csu']\n",
    "\n",
    "# Tags à supprimer\n",
    "tag_list_ga = ['GA:',':GA']\n",
    "tag_list_gp = ['GP:',':GP']               \n",
    "tag_list_nv = [':NV','NV:']\n",
    "tag_list_pv = ['PV:',':PV']\n",
    "tag_list_gr = ['GR:',':GR']\n",
    "tag_list_gn = [':GN','GN:']\n",
    "tag_list_aut = ['sbound','epsilon','ilimp','caimp','meta', 'ce']\n",
    "tag_list_parent = ['parentf','parento']\n",
    "tag_list_aux = ['auxEtre','auxAvoir','etr']\n",
    "tag_list_pro_int = ['pri']\n",
    "tag_list_que = ['que_restr','que']\n",
    "tag_list_coor = ['coo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suppression des tags de la LEFFF_TABLE non utilisés (et des lemmes associés)\n",
    "\n",
    "ATTENTION : Cellule à executer deux fois pour la suppression, il y a un bug lors de la première execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:03:49.412242Z",
     "start_time": "2019-06-25T08:03:48.899604Z"
    }
   },
   "outputs": [],
   "source": [
    "for key in tab:\n",
    "    if key == '_error':\n",
    "        del tab[key]\n",
    "    else :\n",
    "        list_tag_supr = []\n",
    "        for tag in tab[key].keys():\n",
    "            if tag in ['GA:',':GA','GP:',':GP',':NV','NV:',\n",
    "                       'PV:',':PV','GR:',':GR',':GN','GN:',\n",
    "                       'sbound','epsilon','ilimp','caimp',\n",
    "                       'meta', 'ce','parentf','parento',\n",
    "                       'auxEtre','auxAvoir','etr','pri','coo',\n",
    "                       'que_restr','que']:\n",
    "                list_tag_supr.append(tag)\n",
    "        for e in list_tag_supr:\n",
    "            del tab[key][e]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modification des tags restant de la LEFFF_TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:05:28.109067Z",
     "start_time": "2019-06-25T08:03:54.673145Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key in tab:\n",
    "    list_tag = []\n",
    "    \n",
    "    for tag in tab[key].keys():\n",
    "        list_tag.append(tag)\n",
    "        \n",
    "    i=0\n",
    "    while i>=0 and i<len(list_tag):\n",
    "        i += 1\n",
    "        for tag in tab[key].keys():\n",
    "            \n",
    "            if tag == 'np':\n",
    "                nouveau_tag = 'npp'\n",
    "                val = tab[key][tag]\n",
    "                del tab[key][tag]\n",
    "                tab[key][nouveau_tag] = val\n",
    "                break\n",
    "            \n",
    "            elif tag == 'nc_2':\n",
    "                nouveau_tag = 'nc'\n",
    "                val = tab[key][tag]\n",
    "                del tab[key][tag]\n",
    "                tab[key][nouveau_tag] = val\n",
    "                break\n",
    "\n",
    "            elif tag in ['cld','cla','clr','clneg','clg',\n",
    "                       'cll','cln', 'cldr', 'clar']:\n",
    "                if 'cl' not in list_tag:\n",
    "                    nouveau_tag = 'cl'\n",
    "                    del tab[key][tag]\n",
    "                    tab[key][nouveau_tag] = pos_tagger.tag([key])[0][0]\n",
    "                    i -= 1\n",
    "                else:\n",
    "                    del tab[key][tag]\n",
    "                    i -= 1\n",
    "                break\n",
    "\n",
    "            elif tag == 'pres':\n",
    "                nouveau_tag = 'i'\n",
    "                val = tab[key][tag]\n",
    "                del tab[key][tag]\n",
    "                tab[key][nouveau_tag] = val\n",
    "                i -= 1\n",
    "                break\n",
    "\n",
    "            elif tag == 'prel':\n",
    "                nouveau_tag = 'pro'\n",
    "                val = tab[key][tag]\n",
    "                del tab[key][tag]\n",
    "                tab[key][nouveau_tag] = val\n",
    "                i -= 1\n",
    "                break\n",
    "\n",
    "            elif tag in ['poncts','ponctw']:\n",
    "                if 'ponct' not in list_tag:\n",
    "                    nouveau_tag = 'ponct'\n",
    "                    val = tab[key][tag]\n",
    "                    del tab[key][tag]\n",
    "                    i -= 1\n",
    "                    tab[key][nouveau_tag] = val\n",
    "                else:\n",
    "                    del tab[key][tag]\n",
    "                    i -= 1 \n",
    "                break\n",
    "\n",
    "            elif tag in ['adjPref','suffAdj']:\n",
    "                if 'adj' not in list_tag:\n",
    "                    nouveau_tag = 'adj'\n",
    "                    val = tab[key][tag]\n",
    "                    del tab[key][tag]\n",
    "                    i -= 1\n",
    "                    tab[key][nouveau_tag] = val\n",
    "                else:\n",
    "                    del tab[key][tag]\n",
    "                    i -= 1 \n",
    "                break\n",
    "\n",
    "            elif tag in ['advneg','advPref']:\n",
    "                if 'adv' not in list_tag:\n",
    "                    nouveau_tag = 'adv'\n",
    "                    val = tab[key][tag]\n",
    "                    tab[key][nouveau_tag] = val\n",
    "                    del tab[key][tag]\n",
    "                    i -= 1\n",
    "                else:\n",
    "                    del tab[key][tag]\n",
    "                    i -= 1 \n",
    "                break\n",
    "\n",
    "\n",
    "            elif tag in ['csu','coo']:\n",
    "                if 'c' not in list_tag:\n",
    "                    nouveau_tag = 'c'\n",
    "                    val = tab[key][tag]\n",
    "                    del tab[key][tag]\n",
    "                    #i -= 1\n",
    "                    tab[key][nouveau_tag] = val\n",
    "                else:\n",
    "                    del tab[key][tag]\n",
    "                    i -= 1 \n",
    "                break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vérification de la modification effective des tags de la LEFFF_TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:05:28.968769Z",
     "start_time": "2019-06-25T08:05:28.539915Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nc 86234\n",
      "npp 52283\n",
      "v 301207\n",
      "adj 57217\n",
      "ponct 46\n",
      "adv 3820\n",
      "pro 149\n",
      "det 178\n",
      "prep 733\n",
      "c 324\n",
      "i 93\n",
      "cl 62\n"
     ]
    }
   ],
   "source": [
    "tag_list = []\n",
    "tag_list_compt = [0 for i in range(100)]\n",
    "for key in tab:\n",
    "    for tag in tab[key].keys():\n",
    "        if tag not in tag_list:\n",
    "            tag_list.append(tag)\n",
    "            ind = tag_list.index(tag)\n",
    "            tag_list_compt[ind] += 1\n",
    "        else:\n",
    "            ind = tag_list.index(tag)\n",
    "            tag_list_compt[ind] += 1\n",
    "\n",
    "for i in range(len(tag_list)):\n",
    "    print(tag_list[i],tag_list_compt[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions de réduction des tags pour les autres lexiques\n",
    "\n",
    "#### Réduction des tags du StanfordPOSTagger pour correspondre aux tags : ['v', 'nc', 'adj', 'c', 'npp', 'adv', 'det', 'pro', 'prep', 'i', 'ponct', 'cl', 'et']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:05:38.070033Z",
     "start_time": "2019-06-25T08:05:38.062054Z"
    }
   },
   "outputs": [],
   "source": [
    "final_list = ['v', 'nc', 'adj', 'c', 'npp', 'adv', 'det', 'pro', 'prep', 'i', 'ponct', 'cl', 'et']\n",
    "\n",
    "def reduction_tag_stanford(tag):\n",
    "    tag_reduc = ''\n",
    "    if tag in ['VS', 'VINF', 'VPP', 'VPR', 'VIMP']:\n",
    "        tag_reduc = 'V'\n",
    "    elif tag in ['N','PUNC','PREF']:\n",
    "        tag_reduc = 'NC'\n",
    "    elif tag in ['CS', 'CC']:\n",
    "        tag_reduc = 'C'\n",
    "    elif tag in ['CLS', 'CLO', 'CLR']:\n",
    "        tag_reduc = 'CL'\n",
    "    elif tag in ['ADJWH', 'A']:\n",
    "        tag_reduc = 'ADJ'\n",
    "    elif tag == 'ADVWH':\n",
    "        tag_reduc = 'ADV'\n",
    "    elif tag in ['PROREL', 'PROWH']:\n",
    "        tag_reduc = 'PRO'\n",
    "    elif tag in ['DETWH']:\n",
    "        tag_reduc = 'DET'\n",
    "    else:\n",
    "        tag_reduc = tag\n",
    "    return(tag_reduc.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Réduction des tags du Lexique383 pour correspondre aux tags : ['v', 'nc', 'adj', 'c', 'npp', 'adv', 'det', 'pro', 'prep', 'i', 'ponct', 'cl', 'et']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:05:38.082995Z",
     "start_time": "2019-06-25T08:05:38.076017Z"
    }
   },
   "outputs": [],
   "source": [
    "#Liste des tags originels de lexique383 : ['ADV', 'ADJ','PRO', 'PRE', 'NOM', 'VER', 'ONO', 'CON', 'AUX', 'ART', 'EXP']\n",
    "\n",
    "def reduction_tag_lexique383(tag):\n",
    "    nouveau_tag = ''\n",
    "    if tag == 'NOM':\n",
    "        nouveau_tag = 'nc'\n",
    "    elif tag == 'VER' or tag == 'AUX':\n",
    "        nouveau_tag = 'v'\n",
    "    elif tag == 'CON':\n",
    "        nouveau_tag = 'c'\n",
    "    elif tag == 'ONO':\n",
    "        nouveau_tag = 'i'\n",
    "    elif tag == 'ART':\n",
    "        nouveau_tag = 'det'\n",
    "    elif tag == 'PRE':\n",
    "        nouveau_tag = 'prep'\n",
    "    elif tag == 'EXP':\n",
    "        nouveau_tag = 'cl'\n",
    "    else:\n",
    "        nouveau_tag = tag.lower()\n",
    "    return nouveau_tag\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création du lexique final\n",
    "\n",
    "On regroupe les éléments des trois lexiques : \n",
    "\n",
    "- le lexique de la LEFFF_TABLE\n",
    "- lexique383_noLEFFF (préalablement créé)\n",
    "- lexique_spacy_noLEFFF_noLexique383 (préalablement créé)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement de lexique383_noLEFFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:05:38.135853Z",
     "start_time": "2019-06-25T08:05:38.088982Z"
    }
   },
   "outputs": [],
   "source": [
    "lexique383_noLEFFF = []\n",
    "\n",
    "with open('./intermediate_data/lexique383_noLEFFF.txt') as f:\n",
    "        read = csv.reader(f)\n",
    "        for row in read:\n",
    "            lexique383_noLEFFF.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniformisation des tags de lexique383_noLEFFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:05:38.177740Z",
     "start_time": "2019-06-25T08:05:38.138847Z"
    }
   },
   "outputs": [],
   "source": [
    "for row in lexique383_noLEFFF:\n",
    "    tag_lexique383 = row[2]\n",
    "    row[2] = reduction_tag_lexique383(tag_lexique383)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement de lexique_spacy_noLEFFF_noLexique383"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:05:38.302408Z",
     "start_time": "2019-06-25T08:05:38.272488Z"
    }
   },
   "outputs": [],
   "source": [
    "lexique_spacy_noLEFFF_noLexique383 = []\n",
    "\n",
    "with open('./intermediate_data/lexique_spacy_noLEFFF_noLexique383.txt') as f:\n",
    "        read = csv.reader(f)\n",
    "        for row in read:\n",
    "            lexique_spacy_noLEFFF_noLexique383.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniformisation des tags de lexique_spacy_noLEFFF_noLexique383"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:05:38.334321Z",
     "start_time": "2019-06-25T08:05:38.307395Z"
    }
   },
   "outputs": [],
   "source": [
    "for row in lexique_spacy_noLEFFF_noLexique383:\n",
    "    tag = row[2]\n",
    "    row[2] = reduction_tag_stanford(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajouts des nouveaux mots dans la LEFFF_TABLE\n",
    "\n",
    "#### Ajout des mots du fichier lexique383_noLEFFF.txt dont les tags ont été réduits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:05:38.270493Z",
     "start_time": "2019-06-25T08:05:38.203673Z"
    }
   },
   "outputs": [],
   "source": [
    "for row in lexique383_noLEFFF:\n",
    "    tab[row[0]] = {row[2]:row[1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ajout des mots du fichier lexique_spacy_noLEFFF_noLexique383.txt dont les tags ont été réduits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:05:38.350280Z",
     "start_time": "2019-06-25T08:05:38.337315Z"
    }
   },
   "outputs": [],
   "source": [
    "for row in lexique_spacy_noLEFFF_noLexique383:\n",
    "    tab[row[0]] = {row[2]:row[1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation des majuscules des mots du lexique en minuscules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexique = {}\n",
    "\n",
    "for key in tab:\n",
    "    new_key = key.lower()\n",
    "    if new_key != key:\n",
    "        lexique[new_key] = tab[key] \n",
    "    else:\n",
    "        lexique[key] = tab[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajout de quelques lemmes manquants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {\"n'\":{'cl': \"n'\", 'adv': 'ne'},\n",
    "       \"$\":{'nc': 'dollar', 'adj': 'dollar', 'adv': 'dollar', 'det': 'dollar'},\n",
    "       \"£\":{'nc': 'pound', 'adj': 'pound', 'adv': 'pound', 'det': 'pound'},\n",
    "       '€':{'nc': 'euro', 'adj': 'euro', 'adv': 'euro', 'det': 'euro'},\n",
    "       '%':{'nc': 'pourcent', 'adj': 'pourcent', 'det': 'pourcent'},\n",
    "       \"j'\":{'cl': 'je', 'pro': 'je'},\n",
    "       \"appelle\":{'v': 'appeler', 'npp': 'Appelle'},\n",
    "       \"&\":{'nc': 'et', 'c': 'et', 'adv': 'et'}}\n",
    "\n",
    "for key in dic:\n",
    "    if key not in lexique.keys():\n",
    "        lexique[key]=dic[key]\n",
    "    else:\n",
    "        del lexique[key]\n",
    "        lexique[key]=dic[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ecriture du lexique dans le fichier lexique.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T09:03:29.915661Z",
     "start_time": "2019-06-25T09:03:28.368325Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('./final_data/lexique.txt', 'w') as f:\n",
    "    f.write(str(lexique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": "0",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "273.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
