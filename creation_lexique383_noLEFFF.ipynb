{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création du fichier : lexique383_noLEFFF.txt\n",
    "\n",
    "Reprend tous les mots du Lexique 3.83 et les compare aux mots de TABLE_LEFFF utilisés dans le FrenchLefffLemmatizer, et crée le fichier lexique383_noLEFFF.txt contenant les mots à rajouter dans le lexique du FrenchLefffLemmatizer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import nltk\n",
    "from nltk.tag import StanfordPOSTagger\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation du StanfordPOSTagger\n",
    "\n",
    "Il faut peut-être changer les path pour le StanfordPOSTagger et Java (JRE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "jar = './stanford-postagger-full-2018-10-16/stanford-postagger-3.9.2.jar'\n",
    "model = './stanford-postagger-full-2018-10-16/models/french.tagger'\n",
    "java_path = \"C:/Program Files (x86)/Java/jre1.8.0_241/bin/java.exe\"\n",
    "\n",
    "os.environ['JAVAHOME'] = java_path\n",
    "pos_tagger = StanfordPOSTagger(model, jar, encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement de la LEFFF_TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from french_lefff_lemmatizer.french_lefff_lemmatizer import FrenchLefffLemmatizer\n",
    "lemmatizer = FrenchLefffLemmatizer()\n",
    "tab = lemmatizer.LEFFF_TABLE\n",
    "\n",
    "mots_compare = tab.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement du lexique 3.83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexique383 = []\n",
    "\n",
    "with open('./initial_data/lexique383.txt') as f:\n",
    "        read = csv.reader(f)\n",
    "        for row in read:\n",
    "            lexique383.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajout des mots dans le fichier lexique383_noLEFFF.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le crée si il est pas créé, continue au bon endroit sinon\n",
    "        \n",
    "with open('./intermediate_data/lexique383_noLEFFF.txt', 'a') as f:\n",
    "    # On ouvre ou on crée le fichier, puis on regarde où est-ce qu'on s'est arrêté dans l'écriture \n",
    "    ind = 0\n",
    "    if os.path.getsize('./intermediate_data/lexique383_noLEFFF.txt') == 0:\n",
    "        ind = 0\n",
    "    else:\n",
    "        fr = open('./intermediate_data/lexique383_noLEFFF.txt', 'r')\n",
    "        liste_fr = fr.readlines() \n",
    "        row_final = liste_fr[-1].split(',')\n",
    "        row_final_a_chercher = row_final[0:3]\n",
    "        ind = lexique383.index(row_final_a_chercher)+1\n",
    "        fr.close()\n",
    "    # On commence où reprend l'écriture des données grâce à l'indice déterminé précédement\n",
    "    for i in range(ind,len(lexique383)):\n",
    "        words_separated = lexique383[i]\n",
    "        row_act = []\n",
    "        for word in words_separated:\n",
    "            row_act.append(word)\n",
    "        \n",
    "        # On verifie ensuite si le mot est ou non dans la LEFFF_TABLE\n",
    "        presence = False\n",
    "        \n",
    "        for mot_compare in mots_compare:\n",
    "            if row_act[0]==mot_compare:\n",
    "                presence = True\n",
    "                break\n",
    "                \n",
    "        if presence == False:       \n",
    "            res = pos_tagger.tag([row_act[0]])\n",
    "            row_act.append(res[0][1])\n",
    "            f.write(row_act[0]+','+row_act[1]+','+row_act[2]+','+row_act[3]+'\\n')\n",
    "            print(row_act[0])\n",
    "        else:\n",
    "            presence = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
